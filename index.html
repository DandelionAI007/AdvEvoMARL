<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="AdvEvo-MARL: Shaping Internalized Safety through Adversarial Co-Evolution in Multi-Agent Reinforcement Learning – Pan et al.">
  <meta name="description" content="AdvEvo-MARL introduces a co-evolutionary multi-agent reinforcement learning framework to internalize safety in LLM-based multi-agent systems, achieving attack success rates below 20% while preserving or improving task utility.">
  <meta name="keywords" content="multi-agent reinforcement learning, adversarial co-evolution, safety, large language models, internalized safety">
  <meta name="author" content="Zhenyu Pan, Yiting Zhang, Zhuo Liu, Yunlong Tang, Zeliang Zhang, Haozheng Luo, Yuwei Han, Jianshu Zhang, Dennis Wu, Hong-Yu Chen, Haoran Lu, Haoyang Fang, Manling Li, Chenliang Xu, Philip S. Yu, Han Liu">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="AdvEvo-MARL Project Page">
  <meta property="og:title" content="AdvEvo-MARL: Shaping Internalized Safety">
  <meta property="og:description" content="Co-evolutionary MARL for embedding safety in LLM-based multi-agent systems: ASR < 20% with maintained/improved task utility.">
  <meta property="og:url" content="https://YOUR_DOMAIN.com/advevo-marl">
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="AdvEvo-MARL – Research Preview">
  <meta property="article:published_time" content="2025-10-02T00:00:00.000Z">
  <meta property="article:author" content="Zhenyu Pan">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="multi-agent reinforcement learning">
  <meta property="article:tag" content="adversarial co-evolution">
  
  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <meta name="twitter:creator" content="@FIRST_AUTHOR_TWITTER">
  <meta name="twitter:title" content="AdvEvo-MARL: Shaping Internalized Safety">
  <meta name="twitter:description" content="Co-evolutionary MARL to internalize safety: ASR < 20% and task utility maintained or improved.">
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="AdvEvo-MARL – Research Preview">
  
  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="AdvEvo-MARL: Shaping Internalized Safety through Adversarial Co-Evolution in Multi-Agent Reinforcement Learning">
  <meta name="citation_author" content="Pan, Zhenyu">
  <meta name="citation_author" content="Zhang, Yiting">
  <meta name="citation_author" content="Liu, Zhuo">
  <meta name="citation_author" content="Tang, Yunlong">
  <meta name="citation_author" content="Zhang, Zeliang">
  <meta name="citation_author" content="Luo, Haozheng">
  <meta name="citation_author" content="Han, Yuwei">
  <meta name="citation_author" content="Zhang, Jianshu">
  <meta name="citation_author" content="Wu, Dennis">
  <meta name="citation_author" content="Chen, Hong-Yu">
  <meta name="citation_author" content="Lu, Haoran");
  <meta name="citation_author" content="Fang, Haoyang");
  <meta name="citation_author" content="Li, Manling");
  <meta name="citation_author" content="Xu, Chenliang");
  <meta name="citation_author" content="Yu, Philip S.");
  <meta name="citation_author" content="Liu, Han");
  <meta name="citation_publication_date" content="2025");
  <meta name="citation_journal_title" content="arXiv preprint");
  <meta name="citation_pdf_url" content="https://arxiv.org/pdf/2510.01586.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">
  
  <title>AdvEvo-MARL | Pan et al.</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/logo.png">

  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "AdvEvo-MARL: Shaping Internalized Safety through Adversarial Co-Evolution in Multi-Agent Reinforcement Learning",
    "description": "AdvEvo-MARL introduces a co-evolutionary multi-agent RL framework to internalize safety in LLM-based multi-agent systems, achieving attack success rates below 20% while preserving or improving task utility.",
    "author": [
      {
        "@type": "Person",
        "name": "Zhenyu Pan",
        "affiliation": {
          "@type": "Organization",
          "name": "Northwestern University"
        }
      },
      {
        "@type": "Person",
        "name": "Yiting Zhang",
        "affiliation": {
          "@type": "Organization",
          "name": "University of Illinois at Chicago"
        }
      }
    ],
    "datePublished": "2025-10-02",
    "publisher": {
      "@type": "Organization",
      "name": "arXiv"
    },
    "url": "https://YOUR_DOMAIN.com/advevo-marl",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["multi-agent reinforcement learning","adversarial co-evolution","safety","large language model agents"],
    "abstract": "LLM-based multi-agent systems excel at planning, tool use, and role coordination, but their openness and interaction complexity also expose them to jailbreak, prompt-injection, and adversarial collaboration. Existing defenses fall into two lines: (i) self-verification that asks each agent to pre-filter unsafe instructions; (ii) external guard modules. The former often under-performs because a standalone agent lacks sufficient capacity to detect cross-agent unsafe chains and delegation-induced risks; the latter increases system overhead and creates a single-point-of-failure. To solve these challenges, we propose AdvEvo-MARL, a co-evolutionary multi-agent reinforcement learning framework that internalizes safety into task agents. Attackers and defenders evolve together; a public baseline reduces variance and fosters cooperation. Across attack scenarios, AdvEvo-MARL keeps attack success rate (ASR) below 20% while maintaining or improving task accuracy (up to +3.67%).",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/advevo-marl"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "Multi-Agent Reinforcement Learning"
      },
      {
        "@type": "Thing",
        "name": "AI Safety"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "AdvEvo-MARL Team",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>
<body>

  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- More Works Dropdown -->
  <div class="more-works-container">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Our Lab">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>More Works from Our Lab</h4>
        <button class="close-btn" onclick="toggleMoreWorks()">
          <i class="fas fa-times"></i>
        </button>
      </div>
      <div class="works-list">
        <!-- Replace with your lab's related works -->
        <a href="https://arxiv.org/abs/2508.03864" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Evo-MARL: Co-Evolutionary Multi-Agent Reinforcement Learning for Internalized Safety</h5>
            <p>Pan et al., 2025. Internalizing safety via co-evolution in MARL.</p>
            <span class="work-venue">arXiv 2025</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
      </div>
    </div>
  </div>

  <main id="main-content">
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">AdvEvo-MARL: Shaping Internalized Safety through Adversarial Co-Evolution</h1>
              <div class="is-size-5 publication-authors">
                Zhenyu Pan, Yiting Zhang, Zhuo Liu, Yunlong Tang, Zeliang Zhang, Haozheng Luo, Yuwei Han, Jianshu Zhang, Dennis Wu, Hong-Yu Chen, Haoran Lu, Haoyang Fang, Manling Li, Chenliang Xu, Philip S. Yu, Han Liu
              </div>
              <div class="is-size-5 publication-authors">
                <span class="author-block"> Northwestern University ｜ University of Illinois at Chicago ｜ University of Rochester ｜ Carnegie Mellon University </span>
              </div>
              <div class="column has-text-centered">
                <div class="publication-links">
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2510.01586" target="_blank" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon"><i class="fas fa-file-pdf"></i></span>
                      <span>Paper</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a href="https://github.com/YOUR_REPO/advevo-marl" target="_blank" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon"><i class="fab fa-github"></i></span>
                      <span>Code</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Framework Overview -->
    <section class="section hero is-light">
      <div class="container is-max-desktop has-text-centered">
        <img src="static/images/AdvEvo-MARL-framework.png" alt="AdvEvo-MARL Framework Diagram" loading="lazy" style="max-width:100%; height:auto;"/>
        <h2 class="title is-4" style="margin-top:1.5rem;">
          A co-evolutionary multi-agent learning framework where attacker agents and defender agents compete and evolve , embedding safety directly into agents themselves.
        </h2>
      </div>
    </section>
    <!-- End Framework Overview -->

    <!-- Project Introduction -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">Project Introduction</h2>
        <div class="content has-text-justified">
          <p>
            In today’s large-language-model (LLM) based multi-agent systems, agents exhibit advanced capabilities in coding, deep research, and secientific discovery — but they are increasingly vulnerable to jailbreaks, prompt-injection attacks, and adversarial collaboration avenues. Traditional defences either rely on self-verification (each agent filtering unsafe instructions) or on external guard modules policing interactions. These approaches suffer from limited cross-agent insight, added overhead, and single-point failures.
          </p>
          <p>
            We propose <strong>AdvEvo-MARL</strong>, a co-evolutionary multi-agent reinforcement learning framework that internalizes safety by jointly evolving attacker agents (which craft evolving jailbreak-style attacks) and defender/task agents (which learn to perform their tasks while resisting such attacks). A key innovation is the introduction of a <em>public baseline</em> for advantage estimation — within each functional group (attackers or defenders), agents share a group-level mean return to reduce variance and enhance cooperation. Experiments show that our method consistently keeps attack success rates (ASR) below 20% (vs. baselines up to ~38.3%) while maintaining or improving task utility (up to +3.7% improvement). AdvEvo-MARL enables internalized safety and strong utility in LLM-based multi-agent systems, without external guards or added overhead, paving a promising path toward scalable, self-regulating, and intrinsically safe multi-agent intelligence.
          </p>
        </div>
      </div>
    </section>


    
    <!-- Results & Conclusions Carousel Section -->
    <section class="hero is-small">
      <div class="hero-body">
        <div class="container">
          <div id="results-carousel" class="carousel results-carousel">
           <div class="item">
          
            <img src="static/images/main_exp.png" alt="First research result visualization" loading="lazy"  style="width:90%; max-width:800px; height:auto; margin:auto; display:block;"/>
      
            <h2 class="subtitle has-text-centered">
               Safety evaluation across various topologies under three threat scenarios: proactive maclicious agents, corrupted communication message, manipulated user instructions. Our method consistently drives ASR below 20% vs baseline ~38% and maintains CR comparably low.
            </h2>
          </div>
          <div class="item">
         
            <img src="static/images/task_perf.png" alt="Second research result visualization" loading="lazy"  style="width:70%; max-width:800px; height:auto; margin:auto; display:block;"/>
            <h2 class="subtitle has-text-centered">
              Task perfprmance across three benchmarks: AIME'24 & '25 (mathematical reasoning), GPQA (general reasoning), LiveCodeBench (coding). Our methods exhibits up to +3.7% accuracy gain, improving safety with minimal sacrifice or even enhanced task utility. These results show that safety and utility can co-exist and break the typical trade-off where improved safety means worse general capability.
            </h2>
          </div>
          <div class="item">
           
            <img src="static/images/baseline_ab.png" alt="Third research result visualization" loading="lazy"  style="width:90%; max-width:800px; height:auto; margin:auto; display:block;"/>
            <h2 class="subtitle has-text-centered">
              Ablation Study on Public Baseline Mechanism. The use of public baseline demonstrates lower ASR, attacker rewards, and higher task performance, extended response length during training. The public baseline mechanism is key to accelerate adversarial multi-agent training and improve intra-group cooperation.
           </h2>
         </div>
      
      </div>
    </div>
    </div>
    </section>



    <!-- BibTex citation -->
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <div class="bibtex-header">
          <h2 class="title">BibTeX</h2>
          <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
            <i class="fas fa-copy"></i>
            <span class="copy-text">Copy</span>
          </button>
        </div>
        <pre id="bibtex-code"><code>@misc{pan2025advevomarlshapinginternalizedsafety,
      title={AdvEvo-MARL: Shaping Internalized Safety through Adversarial Co-Evolution in Multi-Agent Reinforcement Learning}, 
      author={Zhenyu Pan and Yiting Zhang and Zhuo Liu and Yolo Yunlong Tang and Zeliang Zhang and Haozheng Luo and Yuwei Han and Jianshu Zhang and Dennis Wu and Hong-Yu Chen and Haoran Lu and Haoyang Fang and Manling Li and Chenliang Xu and Philip S. Yu and Han Liu},
      year={2025},
      eprint={2510.01586},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2510.01586}, 
}</code></pre>
      </div>
    </section>

    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p>
                The template is from <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.  
                
                This website is licensed under <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>
  </main>
</body>
</html>
